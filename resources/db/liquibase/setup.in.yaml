---
apiVersion: v1
kind: ConfigMap
metadata:
  name: setup-script-volume-configmap
data:
  setup.sql: |
    --liquibase formatted sql
    --changeset postgres:${XYZCHANGESETID}

    CREATE EXTENSION IF NOT EXISTS vector;
    CREATE EXTENSION IF NOT EXISTS pgml;

    CREATE TABLE IF NOT EXISTS ${XYZSCHEMA}.vmware_doc_scrape_metadata (
      id serial,
      url varchar(1000),
      summary text,
      token text,
      e5_large_token_embedding VECTOR(768)
    );

    CREATE OR REPLACE FUNCTION ${XYZSCHEMA}.run_loader_task(
       url varchar(1000),
       data text,
       chunk_size smallint,
       chunk_overlap smallint)
    RETURNS INT AS
    '
    DECLARE
    return_count int;
    BEGIN
       WITH tokens AS (
          SELECT chunk_index, chunk
          FROM pgml.chunk(
            ''recursive_character'',
            data,
            json_build_object(''chunk_size'',chunk_size,''chunk_overlap'',chunk_overlap)::JSONB
          )
       )
       INSERT INTO ${XYZSCHEMA}.vmware_doc_scrape_metadata(url, token)
       SELECT url, chunk from tokens;
       GET DIAGNOSTICS return_count := ROW_COUNT;
       RETURN return_count;
    END
    '
    LANGUAGE plpgsql;

    CREATE OR REPLACE FUNCTION public.run_llm_inference_task(
           question varchar,
           task varchar,
           task_model varchar,
           use_topk boolean default 'y')
        RETURNS table (
            doc_url varchar,
            result jsonb
        )
        AS
        '
        BEGIN
    		IF use_topk is FALSE THEN
    			RETURN QUERY
    			SELECT ''none'', pgml.transform(
    	            task  => jsonb_build_object(''task'',task,''model'',task_model),
    	            inputs => ARRAY[question]
    	        ) AS result;
    		ELSE
    	        RETURN QUERY
    	        WITH contexts AS (
    	            SELECT pgml.embed(''distilbert-base-uncased'', ''query: '' || question)::vector AS context_question
    	        ),
    	        data AS (
    	            SELECT id,
    	            token,
    	            url,
    	            e5_large_token_embedding  AS embedding,
    	            1-(context_question <=> e5_large_token_embedding) AS cosine_similarity
    	            FROM contexts, vmware_doc_scrape_metadata
    	            ORDER BY context_question <=> e5_large_token_embedding
    	            LIMIT 3
    	        ),
    	        summary AS (
    	            SELECT vmware_doc_scrape_metadata.url AS summary_url,
    	            vmware_doc_scrape_metadata.token AS summary_token
    	            FROM vmware_doc_scrape_metadata, data
    	            WHERE vmware_doc_scrape_metadata.id >= data.id-5 AND vmware_doc_scrape_metadata.id < data.id+5
    	            AND vmware_doc_scrape_metadata.url = data.url
    	            ORDER BY vmware_doc_scrape_metadata.id
    	        )
    	        SELECT summary_url, pgml.transform(
    	            task  => jsonb_build_object(''task'',task,''model'',task_model),
    	            inputs => ARRAY[string_agg(summary_token,'' '' ) ]
    	        ) AS result
    	        FROM summary
    	        GROUP BY summary_url;
    		END IF;
        END;
        '
        LANGUAGE plpgsql;
---
apiVersion: batch/v1
kind: Job
metadata:
  name: liquibase
spec:
  ttlSecondsAfterFinished: 60
  template:
    spec:
      containers:
        - name: liquibase
          image: liquibase/liquibase:latest
          command:
            - liquibase
            - update
            - --changelog-file=changelog/setup.sql
            - --url=jdbc:${DATA_E2E_LIQUIBASE_TRAINING_DB_URI}
            - --username=postgres
            - --password=${DATA_E2E_BITNAMI_AUTH_PASSWORD}
            - --log-level=debug
          volumeMounts:
            - name: setup-script-volume
              mountPath: /liquibase/changelog

      volumes:
        - name: setup-script-volume
          configMap:
            name: setup-script-volume-configmap
      restartPolicy: Never
  backoffLimit: 4